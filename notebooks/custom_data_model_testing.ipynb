{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.baseline_model import MoleculeModel\n",
    "from scripts.utils import generate_descriptors\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_val = pd.read_csv('../data/split/data_train_val.csv')\n",
    "data_test = pd.read_csv('../data/split/data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'active'\n",
    "FP_SIZE = 256\n",
    "FP_RADIUS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04dc4ae90904432a5117000404119b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2234f47ab05483f839f614e873e272d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train_val = generate_descriptors(data_train_val, fp_size=FP_SIZE, fp_radius=FP_RADIUS)\n",
    "data_test = generate_descriptors(data_test, fp_size=FP_SIZE, fp_radius=FP_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ITMO_FS.embedded import MOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = data_train_val.drop(columns = [TARGET_COLUMN, 'smiles'])\n",
    "X_test = data_test.drop(columns = [TARGET_COLUMN, 'smiles'])\n",
    "y_train_val = data_train_val.active\n",
    "y_test = data_test.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.concat([X_train_val, X_test]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(pd.concat([X_train_val, X_test]))\n",
    "X_train_val = scaler.transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = MOS()\n",
    "\n",
    "mos.fit(np.concatenate([X_train_val, X_test], axis=0), pd.concat([y_train_val, y_test]).to_numpy(), feature_names=data_train_val.columns)\n",
    "X_train_val = mos.transform(X_train_val)\n",
    "X_test = mos.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X_train_val, X_test])\n",
    "y = pd.concat([y_train_val, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FpDensityMorgan1\n",
      "BCUT2D_MWHI\n",
      "BCUT2D_MRHI\n",
      "RingCount\n",
      "#amine\n",
      "CNS\n",
      "PISA\n",
      "glob\n",
      "QPlogPC16\n",
      "QPlogPo/w\n",
      "QPlogS\n",
      "CIQPlogS\n",
      "QPlogKp\n",
      "EA(eV)\n",
      "QPlogKhsa\n",
      "HumanOralAbsorption\n",
      "PercentHumanOralAbsorption\n",
      "#ringatoms\n",
      "#in56\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(cols):\n",
    "    if i in mos.selected_features:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(372, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4,  random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model):\n",
    "    '''\n",
    "    Get the model from six state-of-the-art machine learning models.\n",
    "    '''\n",
    "    if model=='svm':\n",
    "        from sklearn.svm import SVC\n",
    "        names = [\"Linear SVM\"]\n",
    "        classifiers = [\n",
    "        SVC()    \n",
    "        ]\n",
    "    elif model=='ab':\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        names = [\"AdaBoost\"]\n",
    "        classifiers = [\n",
    "        AdaBoostClassifier() \n",
    "        ]\n",
    "    elif model=='knn':\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        names = [\"K-Nearest Neighbors\"]\n",
    "        classifiers = [\n",
    "        KNeighborsClassifier()\n",
    "        ]\n",
    "    elif model=='rfc':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        names = [\"Random Forest\"]\n",
    "        classifiers = [\n",
    "        RandomForestClassifier()\n",
    "        ]\n",
    "    elif model=='xgboost':\n",
    "        from xgboost import XGBClassifier\n",
    "        names = [\"XGBoost\"]\n",
    "        classifiers = [\n",
    "        XGBClassifier()\n",
    "        ]\n",
    "    elif model=='mlpclassifier':\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        names = [\"MLPClassifier\"]\n",
    "        classifiers = [\n",
    "        MLPClassifier()\n",
    "        ]\n",
    "    else:\n",
    "        raise RuntimeError('Unknown classifier')\n",
    "    \n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "              'svm': {'model__C': (1, 5, 10, 50, 100), 'model__probability': [True]}, \n",
    "              'ab': {'model__n_estimators': (10, 25, 50, 100, 125, 150, 200)}, \n",
    "              'knn': {'model__n_neighbors': (3, 5, 10, 50, 75, 100), 'model__leaf_size': (1, 2, 3, 5, 10, 15, 20), \n",
    "                      'model__weights': ['uniform', 'distance']}, \n",
    "              'rfc': {'model__max_depth': (2, 3, 5, 7, 10), 'model__n_estimators': (50, 100, 150, 200),\n",
    "                     'model__min_samples_leaf': (1, 3, 5, 10)},\n",
    "              'mlpclassifier': {'model__hidden_layer_sizes': (\n",
    "                                  (25, 50, 25, 10), \n",
    "                                  (10, 15, 10),\n",
    "                                  (30, 50, 20, 10)),\n",
    "                                'model__alpha': (0.0001, 0.001, 0.00001, 0.01), \n",
    "                                'model__learning_rate': ['constant', 'adaptive'],\n",
    "                                'model__max_iter': [500]\n",
    "                               },\n",
    "              'xgboost': {'model__n_estimators': (10, 25, 50, 100)}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for svm: {'model__C': 1, 'model__probability': True}\n",
      "Test ROC AUC for the best model 0.92\n",
      "Test accuracy for the best model 0.85\n",
      "Test f1-score for the best model 0.91\n",
      "\n",
      "Best params for ab: {'model__n_estimators': 10}\n",
      "Test ROC AUC for the best model 0.91\n",
      "Test accuracy for the best model 0.85\n",
      "Test f1-score for the best model 0.90\n",
      "\n",
      "Best params for knn: {'model__leaf_size': 1, 'model__n_neighbors': 75, 'model__weights': 'distance'}\n",
      "Test ROC AUC for the best model 0.95\n",
      "Test accuracy for the best model 0.84\n",
      "Test f1-score for the best model 0.91\n",
      "\n",
      "Best params for rfc: {'model__max_depth': 2, 'model__min_samples_leaf': 5, 'model__n_estimators': 100}\n",
      "Test ROC AUC for the best model 0.93\n",
      "Test accuracy for the best model 0.87\n",
      "Test f1-score for the best model 0.92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizzka239/anaconda3/envs/rdkit/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for mlpclassifier: {'model__alpha': 0.0001, 'model__hidden_layer_sizes': (10, 15, 10), 'model__learning_rate': 'adaptive', 'model__max_iter': 500}\n",
      "Test ROC AUC for the best model 0.93\n",
      "Test accuracy for the best model 0.89\n",
      "Test f1-score for the best model 0.93\n",
      "\n",
      "[11:48:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params for xgboost: {'model__n_estimators': 100}\n",
      "Test ROC AUC for the best model 0.88\n",
      "Test accuracy for the best model 0.81\n",
      "Test f1-score for the best model 0.88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizzka239/anaconda3/envs/rdkit/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/lizzka239/anaconda3/envs/rdkit/lib/python3.9/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/lizzka239/anaconda3/envs/rdkit/lib/python3.9/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/lizzka239/anaconda3/envs/rdkit/lib/python3.9/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_clfs_encode = {}\n",
    "for name, param in parameters.items():\n",
    "    model = get_model(name)[0]\n",
    "    \n",
    "    steps = [('model', model)]\n",
    "\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    clf = GridSearchCV(pipeline, param, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    clf.fit(X_train_val, y_train_val)\n",
    "\n",
    "    print(f'Best params for {name}:', clf.best_params_)\n",
    "    pipe = clf.best_estimator_['model']\n",
    "\n",
    "    print('Test ROC AUC for the best model %.2f' % roc_auc_score(y_test, pipe.predict_proba(X_test)[:,1]))\n",
    "    print('Test accuracy for the best model %.2f' % accuracy_score(y_test, pipe.predict(X_test)))\n",
    "    print('Test f1-score for the best model %.2f' % f1_score(y_test, pipe.predict(X_test)))\n",
    "    print()\n",
    "    best_clfs_encode[name] = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=10, n_estimators=50)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = KNeighborsClassifier(leaf_size=1, n_neighbors=75, weights='distance')\n",
    "model = RandomForestClassifier(max_depth=10, min_samples_leaf=10, n_estimators=50)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/preprocessed/custom_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344abf7b92e64cd481ffc902e0a1a86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = generate_descriptors(test_data, fp_size=FP_SIZE, fp_radius=FP_RADIUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_data.drop(columns=['smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = scaler.transform(test)\n",
    "test = mos.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 19)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predicted'] = pd.Series(predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC/C(=C(\\c1ccccc1)/c1ccc(cc1)OCCN(C)C)/c1ccccc1\n",
      "OC[C@H]1O[C@H]([C@@H]([C@@H]1O)O)n1cnc2c1ncnc2NC1CCCCC1\n",
      "OC(=O)[C@@H](c1ccc(c(c1)F)c1ccccc1)C\n",
      "CCCCNC(=O)NS(=O)(=O)c1ccc(cc1)C\n",
      "COCCOCCCSc1ccc(cn1)C(=O)Nc1ccc(cc1C(=O)O)C#N\n",
      "OCC(=O)[C@@]1(O)[C@H](C)C[C@@H]2[C@]1(C)C[C@H](O)[C@]1([C@H]2CCC2=CC(=O)C=C[C@]12C)F\n",
      "CC(=O)C[C@@H](c1c(=O)oc2c(c1O)cccc2)c1ccccc1\n",
      "OCCOCn1cnc2c1nc(N)[nH]c2=O\n",
      "CN(CC[C@@H](c1ccccn1)c1ccc(cc1)Cl)C\n",
      "OC[C@H]1O[C@H]([C@@H]([C@@H]1O)O)n1cnc2c1ncnc2NC1CC2CC1CC2\n"
     ]
    }
   ],
   "source": [
    "for i in list(test_data[test_data.predicted == 0].smiles):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_csv = test_data[['smiles', 'predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_csv.to_csv('../data/predicted_test/custom_db_predicted.csv', inde)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkitEnv",
   "language": "python",
   "name": "rdkitenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
